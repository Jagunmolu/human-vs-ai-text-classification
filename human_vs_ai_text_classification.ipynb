{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a18915c0-3377-44f6-a5a5-d1650e6b61e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import ComplementNB, MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "# from sklearn.preprocessing import FunctionTransformer\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b475690d-c807-4a52-b82b-4d5a91391cb8",
   "metadata": {},
   "source": [
    "Generated by AI (1) or Human (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17a8db40-c71d-49be-b824-9f898fd62300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = CountVectorizer(stop_words=\"english\", max_df=.8, min_df=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "619eb5dd-a5dd-45af-9b37-cb0859ee2f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_vect = vectorizer.fit_transform(X_train)\n",
    "# X_test_vect = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ea4467a2-8180-450a-9561-12db34df69aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import joblib\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import FunctionTransformer, LabelEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "class Models:\n",
    "    def __init__(self, file_path, model):\n",
    "        self.punctuations = string.punctuation + \"0123456789\"\n",
    "        self.clf = None\n",
    "        self.file_path = file_path\n",
    "        data = self.split_data()\n",
    "        self.X_train = data[0]\n",
    "        self.y_train = data[2]\n",
    "        self.X_test = data[1]\n",
    "        self.y_test = data[3]\n",
    "        # print(self.X_train.shape, self.y_train.shape)\n",
    "        self.pred = None\n",
    "        self.model = model\n",
    "\n",
    "    def split_data(self):\n",
    "        data = self.wrangle()\n",
    "        # X = data.drop(\"generated\", axis=1)\n",
    "        X = data[\"text\"]\n",
    "        y = data[\"generated\"]\n",
    "        # print(X.shape, y.shape)\n",
    "        return train_test_split(X, y, test_size=.25)\n",
    "\n",
    "    def selected_index(self, arr, size=150_000):\n",
    "        np.random.seed(42)\n",
    "        return np.random.choice(arr, size=size, replace=False)\n",
    "        \n",
    "    def wrangle(self):\n",
    "        data = pd.read_csv(self.file_path)\n",
    "        data[\"generated\"] = data[\"generated\"].astype(int)\n",
    "        data = data.dropna()\n",
    "        length = data.shape[0]\n",
    "        np.random.seed(42)\n",
    "        gen0 = data.iloc[self.selected_index(data[data[\"generated\"] == 0].index, 20_000)]\n",
    "        gen1 = data.iloc[self.selected_index(data[data[\"generated\"] == 1].index, 20_000)]\n",
    "        data1 = pd.concat([gen0, gen1], axis=0).reset_index(drop=True)\n",
    "        idx = np.array(data1.index)\n",
    "        np.random.shuffle(idx)\n",
    "        data1 = data1.iloc[idx].reset_index(drop=True)\n",
    "        # data1.to_csv(\"./ai_vs_human.csv\", index=False)\n",
    "        return data1\n",
    "\n",
    "    def random_forest(self):\n",
    "        pass\n",
    "\n",
    "    def svm(self):\n",
    "        pass\n",
    "\n",
    "    def xgboost(self):\n",
    "        pass\n",
    "\n",
    "    def dtree(self):\n",
    "        pass\n",
    "\n",
    "    def nbmul(self):\n",
    "        pass\n",
    "\n",
    "    def nbcom(self):\n",
    "        pass\n",
    "\n",
    "    def knn(self):\n",
    "        pass\n",
    "\n",
    "    def logreg(self):\n",
    "        pass\n",
    "\n",
    "        \n",
    "    def model_init(self, from_file=False):\n",
    "        if from_file:\n",
    "            self.clf = joblib.load(f\"{self.model}.sav\")\n",
    "            self.clf.fit(self.X_train, self.y_train)\n",
    "        else:\n",
    "            if self.model == \"random forest\":\n",
    "                self.clf = make_pipeline(FunctionTransformer(self.remove_punctuations), CountVectorizer(stop_words=\"english\"), RandomForestClassifier(random_state=42))\n",
    "            elif self.model == \"svm\":\n",
    "                self.clf = make_pipeline(FunctionTransformer(self.remove_punctuations), CountVectorizer(stop_words=\"english\"), SVC(random_state=42))\n",
    "            elif self.model == \"xgboost\":\n",
    "                self.clf = make_pipeline(FunctionTransformer(self.remove_punctuations), CountVectorizer(stop_words=\"english\"), XGBClassifier())\n",
    "            elif self.model == \"decision tree\":\n",
    "                self.clf = make_pipeline(FunctionTransformer(self.remove_punctuations), CountVectorizer(stop_words=\"english\"), DecisionTreeClassifier(random_state=42))\n",
    "            elif self.model == \"naive bayes multinomial\":\n",
    "                self.clf = make_pipeline(FunctionTransformer(self.remove_punctuations), CountVectorizer(stop_words=\"english\"), MultinomialNB())\n",
    "            elif self.model == \"naive bayes complement\":\n",
    "                self.clf = make_pipeline(FunctionTransformer(self.remove_punctuations), CountVectorizer(stop_words=\"english\"), ComplementNB())\n",
    "            elif self.model == \"knn\":\n",
    "                self.clf = make_pipeline(FunctionTransformer(self.remove_punctuations), CountVectorizer(stop_words=\"english\"), KNeighborsClassifier())\n",
    "            elif self.model == \"logreg\":\n",
    "                self.clf = make_pipeline(FunctionTransformer(self.remove_punctuations), CountVectorizer(stop_words=\"english\"), LogisticRegression(max_iter=100_000))\n",
    "        \n",
    "            self.clf.fit(self.X_train, self.y_train)\n",
    "            joblib.dump(self.clf, f\"{self.model}.sav\")\n",
    "\n",
    "    def xg_boost(self):\n",
    "        le = LabelEncoder()\n",
    "        y_train_lr = le.fit_transform(self.y_train)\n",
    "        y_test_lr = le.transform(self.y_test)\n",
    "        classes = le.classes_\n",
    "        return y_train_lr, y_test_lr, classes\n",
    "\n",
    "    def metrics(self):\n",
    "        self.pred = self.clf.predict(self.X_test)\n",
    "        # classes = self.clf.classes_\n",
    "        classes = [\"Human\", \"AI\"]\n",
    "        # if self.model == \"xgboost\":\n",
    "        #     class_report = pd.DataFrame(classification_report(self.xg_boost()[1], self.pred, target_names=self.xg_boost()[2], output_dict=True)).transpose()\n",
    "        # else:\n",
    "        class_report = pd.DataFrame(classification_report(self.y_test, self.pred, target_names=classes, output_dict=True)).transpose()\n",
    "        return class_report\n",
    "\n",
    "    def remove_punctuations(self, series):\n",
    "        res = []\n",
    "        for _ in series:\n",
    "            res.append(\"\".join([char for char in _ if char not in self.punctuations]))\n",
    "        return res\n",
    "\n",
    "    def save_fig(self):\n",
    "        # plt.figure(figsize=(10,5))\n",
    "        # if self.model == \"xgboost\":\n",
    "        #     cm = confusion_matrix(self.xg_boost()[1], self.pred)\n",
    "        #     display = ConfusionMatrixDisplay(cm, display_labels=self.xg_boost()[2]).plot()\n",
    "        # else:\n",
    "        cm = confusion_matrix(self.y_test, self.pred)\n",
    "        display = ConfusionMatrixDisplay(cm, display_labels=self.clf.classes_)\n",
    "        display.plot()\n",
    "        plt.grid(False)\n",
    "        plt.savefig(f\"{self.model}.png\")\n",
    "        plt.close()\n",
    "\n",
    "    def final_result(self, from_file):\n",
    "        print(f\"Computing for {self.model}\")\n",
    "        self.model_init(from_file=from_file)\n",
    "        self.metrics()\n",
    "        self.save_fig()\n",
    "\n",
    "    # def process(self):\n",
    "    #     return joblib.loads(f\"{self.model}.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c9bc5023-fa68-4b0d-b174-0ca5d38fd763",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Models(\"./AI_Human.csv\", \"logreg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f5813fe3-5cb3-4e13-af85-f2a7c5e51024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing for logreg\n"
     ]
    }
   ],
   "source": [
    "m.final_result(from_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9112a41b-27f3-41f9-90b1-25bdb58c7959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for _clf in [\"random forest\", \"svm\", \"xgboost\", \"decision tree\", \"naive bayes multinomial\", \"naive bayes complement\", \"knn\", \"logreg\"]:\n",
    "for _clf in [\"random forest\", \"decision tree\", \"naive bayes multinomial\", \"naive bayes complement\", \"logreg\"]:\n",
    "    clfs = Models(\"./AI_Human.csv\", _clf)\n",
    "    clfs.final_result(from_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fcb2b4-4cd0-4a38-9a3a-83bdd15f1a41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "99e7c99d-ce0f-491f-b76b-18c2b06b13d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "X_train = cv.fit_transform(m.X_train)\n",
    "X_test = cv.transform(m.X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a51fa0-56f9-4785-b6ec-74222a4e282c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f93c99f1-f638-462e-97e9-d3703838a3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "what is your name  ben\n",
      "surname  oye\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, ben oye\n"
     ]
    }
   ],
   "source": [
    "name= input(\"what is your name \")\n",
    "surname= input(\"surname \")\n",
    "# print (\"hello \" + name + \" \" + surname)\n",
    "print(f\"Hello, {name} {surname}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "118e938e-d347-4262-8b96-2877efe420e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Human</th>\n",
       "      <td>0.991548</td>\n",
       "      <td>0.9854</td>\n",
       "      <td>0.988464</td>\n",
       "      <td>5000.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AI</th>\n",
       "      <td>0.985490</td>\n",
       "      <td>0.9916</td>\n",
       "      <td>0.988536</td>\n",
       "      <td>5000.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.988500</td>\n",
       "      <td>0.9885</td>\n",
       "      <td>0.988500</td>\n",
       "      <td>0.9885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.988519</td>\n",
       "      <td>0.9885</td>\n",
       "      <td>0.988500</td>\n",
       "      <td>10000.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.988519</td>\n",
       "      <td>0.9885</td>\n",
       "      <td>0.988500</td>\n",
       "      <td>10000.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision  recall  f1-score     support\n",
       "Human          0.991548  0.9854  0.988464   5000.0000\n",
       "AI             0.985490  0.9916  0.988536   5000.0000\n",
       "accuracy       0.988500  0.9885  0.988500      0.9885\n",
       "macro avg      0.988519  0.9885  0.988500  10000.0000\n",
       "weighted avg   0.988519  0.9885  0.988500  10000.0000"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3917721e-8617-4fa1-bace-7e58fb8bafa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
